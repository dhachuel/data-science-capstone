---
title: "Data Science Capstone Project - Milestone Report"
author: "David Hachuel"
date: "February 19, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instructions

The goal of this project is just to display that you've gotten used to working with the data and that you are on track to create your prediction algorithm. Please submit a report on R Pubs (<http://rpubs.com/>) that explains your exploratory analysis and your goals for the eventual app and algorithm. This document should be concise and explain only the major features of the data you have identified and briefly summarize your plans for creating the prediction algorithm and Shiny app in a way that would be understandable to a non-data scientist manager. You should make use of tables and plots to illustrate important summaries of the data set. The motivation for this project is to: 1. Demonstrate that you've downloaded the data and have successfully loaded it in.2. Create a basic report of summary statistics about the data sets.3. Report any interesting findings that you amassed so far.4. Get feedback on your plans for creating a prediction algorithm and Shiny app.

**Review criteria:**

1. Does the link lead to an HTML page describing the exploratory analysis of the training data set?
2. Has the data scientist done basic summaries of the three files? Word counts, line counts and basic data tables?
3. Has the data scientist made basic plots, such as histograms to illustrate features of the data?
4. Was the report written in a brief, concise style, in a way that a non-data scientist manager could appreciate?

## Analysis

### Loading Libraries
```{r, echo=TRUE}
# LOAD LIBRARIES
suppressMessages(require(BBmisc))
suppressAll({
  library(ggplot2)
  library(reshape2)
  library(tm)
  library(slam)
  library(wordcloud)
  library(tokenizers)
  library(stringi)
})
```

```{r, echo=TRUE}
# SET WORKING DIRECTORY
setwd("/home/dhachuel/Dropbox/Johns Hopkins Coursera/Capstone Project")  
```

### Analysis Functions

The following functions will provide basic stats for each file. The main goal is to provide basic statistics regarding the file size, number of lines, number of characters, words per line, and frequency of words. In addition, a few plots will help visualize this information. 

```{r, echo=TRUE}
# BASIC PLOTS (histograms and similar to illustrate data features)
getWordStats <- function(input_text){
  cat("Tokenizing words...\n")
  input_text.words <- unlist(tokenizers::tokenize_words(input_text))
  input_text.words.table <- as.data.frame(table(input_text.words))
  
  cat("Sorting words by decresing frequencies...")
  input_text.words.table <- input_text.words.table[order(-input_text.words.table$Freq) , ]
  
  names(input_text.words.table)[1] <- "Words"
  ggplot(head(input_text.words.table, 10) , aes(x = Words, y = Freq)) + 
    geom_bar(colour="black", stat="identity") +
    ggtitle("Top 10 Words")
}

# BASIC SUMMARY (word counts, line counts and basic data tables)
getBasicTextSummary <- function(filepath, data.name){
  cat("Creating file connection...\n")
  con <- file(filepath, "r")
  
  cat("Reading content from connection instance...\n")
  suppressAll(text <- readLines(con, encoding="UTF-8"))
  
  cat(paste("Summary for file : ", data.name, "\n"))
  
  cat(paste(
    "Size : ",
    round(file.info(summary(con)$description)$size/1048576,2),
    " mb\n"
  ))
  close(con)
  
  general_stats <- stringi::stri_stats_general(text)
  cat(paste(
    "File contains ",
    general_stats['Lines'],
    " lines\n"
  ))
  cat(paste(
    "File contains ",
    general_stats['Chars'],
    " characters\n"
  ))
  
  cat("Tokenizing words in lines...\n")
  count_words <- stringi::stri_count_words(text)
  cat("Count words/line summary:\n")
  print(summary(count_words))
  cat("\n")
  print(qplot(count_words, main = paste(data.name," - Frequency of Words Per Line")))
  
  getWordStats(input_text = text)
}

```

```{r, echo=FALSE}
twitter.filepath <- "/home/dhachuel/Dropbox/Johns Hopkins Coursera/Capstone Project/final/en_US/en_US.twitter.txt"
blogs.filepath <- "/home/dhachuel/Dropbox/Johns Hopkins Coursera/Capstone Project/final/en_US/en_US.blogs.txt"
news.filepath <- "/home/dhachuel/Dropbox/Johns Hopkins Coursera/Capstone Project/final/en_US/en_US.news.txt"
```

### Analysis Results : Twitter text
```{r, echo=TRUE}
suppressMessages({
  getBasicTextSummary(filepath = twitter.filepath, data.name = "Twitter text data")
})
```

### Analysis Results : Blogs text
```{r, echo=TRUE}
suppressMessages({
  getBasicTextSummary(filepath = blogs.filepath, data.name = "Blogs text data")
})
```

### Analysis Results : News text
```{r, echo=TRUE}
suppressMessages({
  getBasicTextSummary(filepath = news.filepath, "News text data")
})
```

## Conclusion
Although each data set has its own characteristics regarding line length, it seems that the distribution of words is fairly similar. In fact, all text samples have almost the same top 10 most frequent words. 